 # ğŸ§  Document Question Answering using OCR

A full-stack AI system that extracts text from scanned documents using OCR and answers questions based on the layout and content using Transformer-based models like LayoutLMv3. Built with Flask, PyTorch, and Hugging Face.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![Flask](https://img.shields.io/badge/Flask-WebApp-lightgrey)
![LayoutLMv3](https://img.shields.io/badge/Model-LayoutLMv3-green)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸ” Project Overview

This project merges **OCR** with **Document Question Answering (DocVQA)** to enable smart understanding of scanned or photographed documents. Users can upload an image, ask a question about its content (like invoice number, date, amount), and the system gives an accurate answer by processing both text and layout.

---

## ğŸ¯ Objectives

- Extract structured text data from documents using OCR
- Use layout-aware models (LayoutLMv3) to comprehend document structure
- Answer natural language questions based on the document content
- Deploy with a clean, responsive web interface using Flask
- Provide fully logged and structured outputs

---

## ğŸ’¡ Real-World Applications

- ğŸ› Government records automation
- ğŸ§¾ Invoice & receipt parsing
- ğŸ¥ Medical report extraction
- ğŸ“š Educational transcripts analysis
- ğŸ“‘ Enterprise document summarization

---

## ğŸ› ï¸ Tech Stack

**Languages & Frameworks**
- Python 3.8+
- Flask (Web UI & Backend)

**OCR Engine**
- Tesseract / PaddleOCR

**Transformers**
- Hugging Face Transformers
- LayoutLMv3 / LayoutLM

**Other Tools**
- PyTorch
- OpenCV
- JSON / Logging

---

## ğŸ“ Project Structure

docqa-ocr/
â”œâ”€â”€ app.py # Flask server
â”œâ”€â”€ requirements.txt # All Python dependencies
â”œâ”€â”€ README.md # This file
â”‚
â”œâ”€â”€ inference/
â”‚ â”œâ”€â”€ inference.py # Handles the question-answering process
â”‚ â””â”€â”€ images/ # Folder for uploaded document images
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ model_loader.py # Loads pretrained QA model and processor
â”‚
â”œâ”€â”€ ocr/
â”‚ â””â”€â”€ ocr_extractor.py # Extracts text and layout from images
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ train.log
â”‚ â””â”€â”€ result.json
â”‚
â”œâ”€â”€ results/
â”‚ â””â”€â”€ answer_output.txt
â”‚
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Frontend form and display
â”‚
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ style.css # UI styles
â”‚ â””â”€â”€ script.js # (Optional) JS interactions


---

## ğŸš€ Features

- ğŸ“· **OCR-Powered Document Input**
- ğŸ§  **Layout-Aware QA with LayoutLMv3**
- ğŸ–¥ **Clean Flask-based Web Interface**
- ğŸ”„ **Fully Automatic Pipeline**
- ğŸ“‚ **Structured Logs and Result Files**
- âœ… **Works with Invoices, Bills, Receipts, Forms, and more**

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/docqa-ocr.git
cd docqa-ocr

2. Create a Virtual Environment (optional but recommended)
bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
3. Install Requirements
bash
Copy
Edit
pip install -r requirements.txt
4. Download & Load Model Weights
The model is downloaded automatically via Hugging Face when first used.

Example (already in model_loader.py):

python
Copy
Edit
from transformers import LayoutLMv3Processor, LayoutLMv3ForQuestionAnswering

processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base")
model = LayoutLMv3ForQuestionAnswering.from_pretrained("microsoft/layoutlmv3-base")
5. Run the Application
bash
Copy
Edit
python app.py
Access the app at: http://127.0.0.1:5000

ğŸ–¼ Architecture Diagram
        [User Upload]
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   OCR (Tesseract)    â”‚ â† Text + Layout
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LayoutLMv3 Processor â”‚ â† Tokenization + Bounding Boxes
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LayoutLMv3 Model     â”‚ â† QA Task
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
       [Answer Displayed]
ğŸ“¬ Contact
ğŸ‘¤ Your Name

ğŸ”— GitHub: https://github.com/yourusername

ğŸ“§ Email: sujeetmalagundi999@gmail.com

ğŸ™ Acknowledgements
Hugging Face Transformers

Tesseract OCR

Microsoft LayoutLMv3

PaddleOCR
